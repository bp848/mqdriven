import pdfplumber
import csv
import re
import os
from pathlib import Path

# =============================
# è¨­å®š
# =============================
# ãƒ¦ãƒ¼ã‚¶ãƒ¼ç’°å¢ƒã®ãƒ‘ã‚¹ï¼ˆãã®ã¾ã¾ç¶­æŒï¼‰
OUTPUT_DIR = r"C:\Users\ishij\Downloads\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨-20260219T030449Z-1-001\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨\csvå‡ºåŠ›"

# å„æœŸã®ã€Œæœ€çµ‚ç‰ˆã®ã¿ã€ã‚’ä½¿ç”¨ï¼ˆé€”ä¸­æœˆã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯é™¤å¤–ï¼‰
# â€» åŒã˜æœŸã§è¤‡æ•°ã‚ã‚‹å ´åˆã€æœ€ã‚‚æœŸé–“ãŒé•·ã„ã‚‚ã®ï¼ˆé€šæœŸï¼‰ã ã‘æ®‹ã™
PDF_FILES = {
    # æœŸå: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    "ç¬¬75æœŸ": r"C:\Users\ishij\Downloads\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨-20260219T030449Z-1-001\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨\ç¬¬75æœŸã€€2015.06-05ã€€ãŠå®¢æ§˜ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨.pdf",
    "ç¬¬76æœŸ": r"C:\Users\ishij\Downloads\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨-20260219T030449Z-1-001\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨\ç¬¬76æœŸã€€2016.06-05ã€€ãŠå®¢æ§˜ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨02 (1).pdf",
    "ç¬¬77æœŸ": r"C:\Users\ishij\Downloads\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨-20260219T030449Z-1-001\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨\ç¬¬77æœŸã€€2017.06-05ã€€ãŠå®¢æ§˜ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨_é †ä½.pdf",
    "ç¬¬78æœŸ": r"C:\Users\ishij\Downloads\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨-20260219T030449Z-1-001\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨\ç¬¬78æœŸ 2018.06-05 ãŠå®¢æ§˜ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨_é †ä½åˆ¥.pdf",
    "ç¬¬79æœŸ": r"C:\Users\ishij\Downloads\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨-20260219T030449Z-1-001\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨\ç¬¬79æœŸ 2020.06-05 ãŠå®¢æ§˜ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨_æœ€çµ‚_é †ä½åˆ¥.pdf",
    "ç¬¬80æœŸ": r"C:\Users\ishij\Downloads\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨-20260219T030449Z-1-001\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨\ç¬¬80æœŸ 2020.06-05 ãŠå®¢æ§˜ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨_é †ä½åˆ¥ .pdf",
    "ç¬¬81æœŸ_é †ä½": r"C:\Users\ishij\Downloads\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨-20260219T030449Z-1-001\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨\ç¬¬81æœŸ 2021.06-05 ãŠå®¢æ§˜ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨(é †ä½).pdf",
    "ç¬¬81æœŸ_æ‹…å½“": r"C:\Users\ishij\Downloads\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨-20260219T030449Z-1-001\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨\ç¬¬81æœŸãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨(æ‹…å½“åˆ¥).pdf",
    "ç¬¬82æœŸ_é †ä½": r"C:\Users\ishij\Downloads\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨-20260219T030449Z-1-001\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨\ç¬¬82æœŸ 2022.06-2023.05 ãŠå®¢æ§˜ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨_é †ä½åˆ¥.pdf", 
    "ç¬¬82æœŸ_æ‹…å½“": r"C:\Users\ishij\Downloads\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨-20260219T030449Z-1-001\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨\ç¬¬82æœŸ 2022.06-12 ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨(æ‹…å½“åˆ¥).pdf",
    "ç¬¬83æœŸ_é †ä½": r"C:\Users\ishij\Downloads\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨-20260219T030449Z-1-001\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨\ç¬¬83æœŸ 2023.06-2024.05 ãŠå®¢æ§˜ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨.pdf",
    "ç¬¬83æœŸ_æ‹…å½“": r"C:\Users\ishij\Downloads\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨-20260219T030449Z-1-001\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨\ç¬¬83æœŸ 2023.06-2024.05æ‹…å½“åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨.pdf",
    "ç¬¬84æœŸ_é †ä½": r"C:\Users\ishij\Downloads\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨-20260219T030449Z-1-001\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨\ç¬¬84æœŸ 2024.06-2025.05 ãŠå®¢æ§˜ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨.pdf",
    "ç¬¬84æœŸ_æ‹…å½“": r"C:\Users\ishij\Downloads\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨-20260219T030449Z-1-001\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨\ç¬¬84æœŸ 2024.06-2025.05 æ‹…å½“åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨.pdf",
    "2005-2006": r"C:\Users\ishij\Downloads\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨-20260219T030449Z-1-001\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨\20051001ï½ 20060930ã€€å£²ä¸Šé †ä½è¡¨ï¼ˆä¸Šä½300ç¤¾).pdf",
    "2006-2007": r"C:\Users\ishij\Downloads\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨-20260219T030449Z-1-001\ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨\20061001ï½ 20070930ã€€å£²ä¸Šé †ä½è¡¨ï¼ˆ500ç¤¾ï¼‰.pdf",
}

# Supabase fiscal_periodsãƒ†ãƒ¼ãƒ–ãƒ«ã®IDãƒãƒƒãƒ—
# SELECT period_name, id FROM fiscal_periods ORDER BY start_date; ã®çµæœã«åŸºã¥ã
PERIOD_ID_MAP = {
    # ç¬¬75æœŸ (2015-06-01 ~ 2016-05-31)
    "ç¬¬75æœŸ": "85f5223a-1d17-406d-94c6-e10708faa472",
    # ç¬¬76æœŸ (2016-06-01 ~ 2017-05-31)
    "ç¬¬76æœŸ": "e144e2ff-25b1-46da-a368-7df8959aaa4e",
    # ç¬¬77æœŸ (2017-06-01 ~ 2018-05-31)
    "ç¬¬77æœŸ": "a9c906b2-de3b-437e-ae10-dcbf7007b9a9",
    # ç¬¬78æœŸ (2018-06-01 ~ 2019-05-31)
    "ç¬¬78æœŸ": "5e6c15e5-0f32-436a-aadb-8bb67b403f67",
    # ç¬¬79æœŸ (2019-06-01 ~ 2020-05-31)
    "ç¬¬79æœŸ": "70fe82b2-9638-4c66-acb3-56a063128099",
    # ç¬¬80æœŸ (2020-06-01 ~ 2021-05-31)
    "ç¬¬80æœŸ": "23ac2561-e779-4394-aa14-23bcfd421b06",
    
    # ç¬¬81æœŸ (2021-06-01 ~ 2022-05-31)
    "ç¬¬81æœŸ_é †ä½": "0bfc3c17-787f-4da4-b5f7-305850bb12c0",
    "ç¬¬81æœŸ_æ‹…å½“": "0bfc3c17-787f-4da4-b5f7-305850bb12c0",
    
    # ç¬¬82æœŸ (2022-06-01 ~ 2023-05-31)
    "ç¬¬82æœŸ_é †ä½": "514abe0a-2e7e-40ba-86b8-d5225484d5f3",
    "ç¬¬82æœŸ_æ‹…å½“": "514abe0a-2e7e-40ba-86b8-d5225484d5f3",
    
    # ç¬¬83æœŸ (2023-06-01 ~ 2024-05-31)
    "ç¬¬83æœŸ_é †ä½": "c588c222-2584-4d31-bffd-615a4bea7b2c",
    "ç¬¬83æœŸ_æ‹…å½“": "c588c222-2584-4d31-bffd-615a4bea7b2c",
    
    # ç¬¬84æœŸ (2024-06-01 ~ 2025-05-31)
    "ç¬¬84æœŸ_é †ä½": "ea6a6e35-2c65-4ca0-8dfc-4196959a2984",
    "ç¬¬84æœŸ_æ‹…å½“": "ea6a6e35-2c65-4ca0-8dfc-4196959a2984",

    # æ³¨æ„: 2005-2006, 2006-2007ã¯DBã«å­˜åœ¨ã—ãªã„ãŸã‚ã€UUIDã¯å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¾ã›ã‚“ã€‚
}


# =============================
# PDF â†’ è¡Œãƒ‡ãƒ¼ã‚¿æŠ½å‡º
# =============================
def extract_rows(pdf_path):
    rows = []
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages:
                tables = page.extract_tables()
                if tables:
                    for table in tables:
                        for row in table:
                            if row and any(cell for cell in row if cell):
                                rows.append([str(c).strip() if c else "" for c in row])
                else:
                    text = page.extract_text()
                    if text:
                        for line in text.splitlines():
                            line = line.strip()
                            if line:
                                rows.append([line])
    except Exception as e:
        print(f"  âš ï¸  {Path(pdf_path).name}: {e}")
    return rows

# =============================
# é‡è¤‡è¡Œã®é™¤å»
# =============================
def deduplicate_rows(rows):
    seen = set()
    result = []
    for row in rows:
        key = tuple(row)
        if key not in seen:
            seen.add(key)
            result.append(row)
    return result

# =============================
# 1ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
# =============================
def process_one(label, pdf_path, output_dir):
    pdf_path = Path(pdf_path)
    if not pdf_path.exists():
        print(f"  âŒ è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pdf_path.name}")
        return []

    print(f"  ğŸ“„ [{label}] {pdf_path.name}")
    rows = extract_rows(str(pdf_path))
    rows = deduplicate_rows(rows)
    
    # ----------------------------------------------------
    # UUIDã®ä»˜ä¸ (Supabaseã‚¤ãƒ³ãƒãƒ¼ãƒˆç”¨)
    # ----------------------------------------------------
    period_id = PERIOD_ID_MAP.get(label)
    
    # Supabaseã‚¤ãƒ³ãƒãƒ¼ãƒˆç”¨ã®ã‚¯ãƒªãƒ¼ãƒ³ãªãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    # 1åˆ—ç›®ã«fiscal_period_idã‚’è¿½åŠ 
    import_ready_rows = []
    
    if rows:
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã®åˆ¤å®šï¼ˆç°¡æ˜“çš„ï¼‰
        # ã‚‚ã—1è¡Œç›®ã«ã€Œé †ä½ã€ã€ŒNoã€ã€ŒRankã€ãªã©ã®è¨€è‘‰ãŒå«ã¾ã‚Œã¦ã„ã‚Œã°ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ã¿ãªã™
        header_keywords = ["é †ä½", "No", "Rank", "å¾—æ„å…ˆå", "æ°å", "æ‹…å½“"]
        first_row = rows[0]
        is_header = any(keyword in str(cell) for cell in first_row for keyword in header_keywords)
        
        for i, row in enumerate(rows):
            if i == 0 and is_header:
                # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã«ã¯è­˜åˆ¥å­ã‚’å…¥ã‚Œã‚‹
                new_row = ["fiscal_period_id"] + row
            else:
                # ãƒ‡ãƒ¼ã‚¿è¡Œã«ã¯UUIDã‚’å…¥ã‚Œã‚‹ï¼ˆãªã‘ã‚Œã°ç©ºæ–‡å­—ï¼‰
                new_row = [period_id if period_id else ""] + row
            import_ready_rows.append(new_row)
    else:
        import_ready_rows = []

    # 1. å…ƒã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€šã‚Šã®CSVå‡ºåŠ› (ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ã)
    out_path = Path(output_dir) / f"{label}.csv"
    with open(out_path, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.writer(f)
        writer.writerow(["# æœŸãƒ»åŒºåˆ†", label, "å…ƒãƒ•ã‚¡ã‚¤ãƒ«", pdf_path.name, "FiscalPeriodID", period_id])
        writer.writerow([])
        writer.writerows(rows)

    # 2. Supabaseã‚¤ãƒ³ãƒãƒ¼ãƒˆç”¨CSVå‡ºåŠ› (ã‚¯ãƒªãƒ¼ãƒ³ã€UUIDä»˜ã)
    # ã‚«ãƒ©ãƒ åãŒä¸€è‡´ã—ãªã„ã¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ããªã„å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ãƒ˜ãƒƒãƒ€ãƒ¼ã‚‚é‡è¦
    # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜
    import_dir = Path(output_dir) / "supabase_import"
    os.makedirs(import_dir, exist_ok=True)
    import_path = import_dir / f"{label}_import.csv"
    
    with open(import_path, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.writer(f)
        writer.writerows(import_ready_rows)

    print(f"     â†’ âœ… {len(rows)} è¡Œ")
    print(f"        å‡ºåŠ›1: {out_path.name}")
    print(f"        å‡ºåŠ›2: {import_path.name} (Supabaseç”¨)")
    
    return rows

# =============================
# çµ±åˆCSVä½œæˆ
# =============================
def create_combined(all_data, output_dir):
    out_path = Path(output_dir) / "ã€çµ±åˆãƒ»é‡è¤‡é™¤å»æ¸ˆã¿ã€‘å…¨æœŸé–“ãƒ©ãƒ³ã‚­ãƒ³ã‚°.csv"
    with open(out_path, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.writer(f)
        writer.writerow(["æœŸãƒ»åŒºåˆ†", "å†…å®¹"])
        for label, rows in all_data.items():
            writer.writerow([])
            writer.writerow([f"=== {label} ==="])
            writer.writerows(rows)
    print(f"\nğŸ“Š çµ±åˆCSV: {out_path.name}")

# =============================
# ãƒ¡ã‚¤ãƒ³
# =============================
def main():
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    print(f"ğŸ“ å‡ºåŠ›å…ˆ: {OUTPUT_DIR}")
    print(f"âœ… å‡¦ç†å¯¾è±¡: {len(PDF_FILES)} ä»¶\n{'='*50}\n")

    all_data = {}
    for label, path in PDF_FILES.items():
        rows = process_one(label, path, OUTPUT_DIR)
        if rows:
            all_data[label] = rows

    create_combined(all_data, OUTPUT_DIR)
    print(f"\n{'='*50}")
    print(f"âœ… å®Œäº†ï¼")
    print(f"â„¹ï¸  Supabaseã¸ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«ã¯ 'csvå‡ºåŠ›/supabase_import' ãƒ•ã‚©ãƒ«ãƒ€å†…ã®CSVã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
    print(f"â„¹ï¸  '2005-2006'ãªã©ã¯DBã«ç™»éŒ²ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€UUIDåˆ—ã¯ç©ºã«ãªã£ã¦ã„ã¾ã™ã€‚")

if __name__ == "__main__":
    main()
